{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gensim_Part_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTSJvfTKH0zIMWhClU0AwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khuloodnasher/Gensim/blob/main/Gensim_Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iyc3rlYhuYn0",
        "outputId": "45824901-52a2-471d-a2ba-ef272bdd6cef"
      },
      "source": [
        "pip install --upgrade gensim\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/dd/5e00b6e788a9c522b48f9df10472b2017102ffa65b10bc657471e0713542/gensim-4.0.0-cp37-cp37m-manylinux1_x86_64.whl (23.9MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9MB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (4.2.0)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-OeN_y-whby",
        "outputId": "8627e1ee-e954-41b3-fd1c-41aa138e5b09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv_PIaosu6ud",
        "outputId": "393bb3eb-671f-49a2-cbf5-306459f4120e"
      },
      "source": [
        "from gensim import corpora\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGMJ2h2E4nZ7"
      },
      "source": [
        "Create a dictionary  from a list of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0nOcB6FvkO6"
      },
      "source": [
        "my_documents=[\"There is no better way to dive into other cultures\",\"Netflix is making this easier than ever\",\n",
        "              \"they support regional filmmakers around the world\",\n",
        "\"They  makes their work available to international audiences\"]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXIsyYsEyesG",
        "outputId": "baed4c63-7e08-4e70-dac4-5b929d56c8f8"
      },
      "source": [
        "# Tokenizing\n",
        "texts=[[text for text in doc.split()] for doc in my_documents]\n",
        "print(texts)\n",
        "my_dictionary=corpora.Dictionary(texts)\n",
        "\n",
        "print(\"\\n\",my_dictionary)\n",
        "\n",
        "print(\"\\n\",my_dictionary.token2id)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['There', 'is', 'no', 'better', 'way', 'to', 'dive', 'into', 'other', 'cultures'], ['Netflix', 'is', 'making', 'this', 'easier', 'than', 'ever'], ['they', 'support', 'regional', 'filmmakers', 'around', 'the', 'world'], ['They', 'makes', 'their', 'work', 'available', 'to', 'international', 'audiences']]\n",
            "\n",
            " Dictionary(30 unique tokens: ['There', 'better', 'cultures', 'dive', 'into']...)\n",
            "\n",
            " {'There': 0, 'better': 1, 'cultures': 2, 'dive': 3, 'into': 4, 'is': 5, 'no': 6, 'other': 7, 'to': 8, 'way': 9, 'Netflix': 10, 'easier': 11, 'ever': 12, 'making': 13, 'than': 14, 'this': 15, 'around': 16, 'filmmakers': 17, 'regional': 18, 'support': 19, 'the': 20, 'they': 21, 'world': 22, 'They': 23, 'audiences': 24, 'available': 25, 'international': 26, 'makes': 27, 'their': 28, 'work': 29}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moDcpxiEzdPB",
        "outputId": "124b3e35-d4be-4e0c-f479-84b959ce6f37"
      },
      "source": [
        "# displaying  my dictionary in vertical order\n",
        "tokens=[[token for token in sentence.split()] for sentence in my_documents]\n",
        "gensim_dictionary=corpora.Dictionary(tokens)\n",
        "for word,id in gensim_dictionary.token2id.items():\n",
        "    print(f'{word:{12}} {id:{10}}')\n",
        " \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There                 0\n",
            "better                1\n",
            "cultures              2\n",
            "dive                  3\n",
            "into                  4\n",
            "is                    5\n",
            "no                    6\n",
            "other                 7\n",
            "to                    8\n",
            "way                   9\n",
            "Netflix              10\n",
            "easier               11\n",
            "ever                 12\n",
            "making               13\n",
            "than                 14\n",
            "this                 15\n",
            "around               16\n",
            "filmmakers           17\n",
            "regional             18\n",
            "support              19\n",
            "the                  20\n",
            "they                 21\n",
            "world                22\n",
            "They                 23\n",
            "audiences            24\n",
            "available            25\n",
            "international         26\n",
            "makes                27\n",
            "their                28\n",
            "work                 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N9L9srkx7dz"
      },
      "source": [
        "Reading Text file by gensim and  create gensim dictionary from a single txt file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZZSkxMxBs7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b746e097-964e-433d-c50a-100659085046"
      },
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "from gensim import corpora\n",
        "# Tokenize the text file through simple_preprocess and put every word into a dictionary\n",
        "dictionary=corpora.Dictionary(simple_preprocess(line,deacc=True)\n",
        "# Reading the text file\n",
        "for line in open('/content/drive/MyDrive/NLU.txt',encoding=\"utf-8\"))\n",
        "# giving each token word an id\n",
        "print(dictionary.token2id)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ability': 0, 'across': 1, 'after': 2, 'algorithm': 3, 'all': 4, 'also': 5, 'among': 6, 'and': 7, 'apple': 8, 'applied': 9, 'art': 10, 'as': 11, 'associated': 12, 'at': 13, 'be': 14, 'before': 15, 'building': 16, 'closely': 17, 'code': 18, 'collaborating': 19, 'concrete': 20, 'conjunction': 21, 'deep': 22, 'design': 23, 'developed': 24, 'device': 25, 'do': 26, 'emphasis': 27, 'empirical': 28, 'engineering': 29, 'entire': 30, 'experience': 31, 'experiences': 32, 'experimentation': 33, 'facing': 34, 'feature': 35, 'features': 36, 'for': 37, 'foundational': 38, 'frameworks': 39, 'from': 40, 'fundamentals': 41, 'gamut': 42, 'hands': 43, 'harness': 44, 'implementation': 45, 'important': 46, 'in': 47, 'inputs': 48, 'integrate': 49, 'intersection': 50, 'into': 51, 'is': 52, 'language': 53, 'launch': 54, 'learning': 55, 'leverage': 56, 'machine': 57, 'member': 58, 'ml': 59, 'modal': 60, 'models': 61, 'most': 62, 'multi': 63, 'multiple': 64, 'natural': 65, 'nlp': 66, 'of': 67, 'on': 68, 'organizations': 69, 'os': 70, 'our': 71, 'platforms': 72, 'position': 73, 'primary': 74, 'processing': 75, 'product': 76, 'production': 77, 'productizing': 78, 'proven': 79, 'quality': 80, 'range': 81, 'required': 82, 'requires': 83, 'research': 84, 'responsible': 85, 'role': 86, 'several': 87, 'since': 88, 'skillsets': 89, 'software': 90, 'solutions': 91, 'spans': 92, 'stack': 93, 'state': 94, 'strong': 95, 'team': 96, 'teams': 97, 'text': 98, 'that': 99, 'the': 100, 'them': 101, 'this': 102, 'to': 103, 'translate': 104, 'understanding': 105, 'user': 106, 'we': 107, 'will': 108, 'with': 109, 'work': 110, 'working': 111, 'would': 112, 'you': 113}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o55YTMoi2niJ"
      },
      "source": [
        "#Creating Bag of words from a Text File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y67dp1xtltOR",
        "outputId": "5b456469-ef54-4a24-f402-29a62235798e"
      },
      "source": [
        "# Reading text file and Tokenize the text file into tokens through simple_preprocess\n",
        "tokens=[simple_preprocess(line,deacc=True)  for line in open(r'/content/drive/MyDrive/NLU.txt',encoding=\"utf-8\")]\n",
        "# puting tokens inside dictionary, and create bag of words\n",
        "gensim_corpus=[corpora.Dictionary().doc2bow(token,allow_update=True) for  token in tokens]\n",
        "\n",
        "word_frequencies=[[(gensim_dictionary[id],frequence) for id, frequence in couple] for couple in gensim_corpus]\n",
        "\n",
        "print(word_frequencies)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('ability', 2), ('across', 2), ('after', 1), ('algorithm', 1), ('all', 1), ('also', 1), ('among', 1), ('and', 6), ('apple', 2), ('applied', 2), ('art', 1), ('as', 1), ('associated', 1), ('at', 1), ('be', 1), ('before', 1), ('building', 1), ('closely', 2), ('code', 1), ('collaborating', 1), ('concrete', 1), ('conjunction', 1), ('deep', 1), ('design', 1), ('developed', 1), ('device', 1), ('do', 1), ('emphasis', 1), ('empirical', 1), ('engineering', 2), ('entire', 1), ('experience', 1), ('experiences', 1), ('experimentation', 1), ('facing', 1), ('feature', 1), ('features', 2), ('for', 3), ('foundational', 1), ('frameworks', 1), ('from', 1), ('fundamentals', 1), ('gamut', 1), ('hands', 1), ('harness', 1), ('implementation', 1), ('important', 1), ('in', 2), ('inputs', 1), ('integrate', 1), ('intersection', 1), ('into', 2), ('is', 2), ('language', 2), ('launch', 1), ('learning', 1), ('leverage', 1), ('machine', 1), ('member', 1), ('ml', 3), ('modal', 1), ('models', 1), ('most', 1), ('multi', 1), ('multiple', 1), ('natural', 1), ('nlp', 7), ('of', 5), ('on', 5), ('organizations', 1), ('os', 1), ('our', 2), ('platforms', 1), ('position', 2), ('primary', 1), ('processing', 4), ('product', 1), ('production', 2), ('productizing', 1), ('proven', 1), ('quality', 1), ('range', 1), ('required', 1), ('requires', 1), ('research', 1), ('responsible', 1), ('role', 1), ('several', 1), ('since', 1), ('skillsets', 1), ('software', 2), ('solutions', 1), ('spans', 1), ('stack', 1), ('state', 1), ('strong', 1), ('team', 2), ('teams', 2), ('text', 3), ('that', 1), ('the', 11), ('them', 1), ('this', 1), ('to', 5), ('translate', 1), ('understanding', 1), ('user', 1), ('we', 1), ('will', 3), ('with', 5), ('work', 3), ('working', 1), ('would', 1), ('you', 2)], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5CZt9DY3UOA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}